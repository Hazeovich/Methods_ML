{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "def entropy(y: np.ndarray):\n",
    "    p = np.unique(y, return_counts=True)[1]/len(y)\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "def gini(y: np.ndarray):\n",
    "    p = np.unique(y, return_counts=True)[1]/len(y)\n",
    "    return np.sum(p * (1 - p))\n",
    "\n",
    "def var(y: np.ndarray):\n",
    "    return np.var(y)\n",
    "\n",
    "def split(X: np.ndarray, y: np.ndarray, threshold: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    m = X <= threshold\n",
    "    return y[np.invert(m)], y[m]\n",
    "    \n",
    "\n",
    "def tree_split(X, y, criterion):\n",
    "    criter_dict = {'entropy':entropy, 'gini':gini, 'var':var }\n",
    "    H = criter_dict[criterion]\n",
    "    \n",
    "    search_idx = None\n",
    "    \n",
    "    min_ent = np.inf\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(X.shape[0]):\n",
    "            \n",
    "            threshold = X[j, i]\n",
    "            left, right = split(X[:, i], y, threshold)\n",
    "            \n",
    "            ent = H(left) * left.shape[0] / X.shape[0] + \\\n",
    "                    H(right) * right.shape[0] / X.shape[0]\n",
    "            \n",
    "            if ent < min_ent:\n",
    "                min_ent = ent\n",
    "                search_idx = [i, j]\n",
    "    return search_idx\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.98582635  0.75764539  3.25288892 ...  2.91146758  4.57137698\n",
      "   2.15453668]\n",
      " [-1.30624563  2.41190754  1.65850954 ... -4.69231805 -0.02520994\n",
      "   0.2523196 ]\n",
      " [-1.30663851 -3.58519116  2.0271222  ...  1.02812272 -1.63835972\n",
      "   0.21451276]\n",
      " ...\n",
      " [ 0.2770626   0.00925033 -0.3426235  ...  1.79838569 -1.80086054\n",
      "   2.54411797]\n",
      " [ 3.14466674  2.51669085  3.18947342 ... -2.64706015 -2.18573452\n",
      "   3.43117551]\n",
      " [-1.6955388  -0.29775785 -2.76471767 ...  1.18399405 -3.31532382\n",
      "   0.53611124]] [1 1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1\n",
      " 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1\n",
      " 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X, y = sklearn.datasets.make_classification(n_samples=100, n_features=20, n_informative=20, n_redundant=0, n_clusters_per_class=2)\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79, 5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_split(X, y, 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
